# ğŸ’» Proyecto de Machine Learning

## ğŸ¶ğŸ±ğŸ¾ ClasificaciÃ³n de adoptadibilidad de mascotas ğŸ°ğŸ¹ğŸ²

Este es un **proyecto para el curso de Machine Learning**, en el que se principalmente se busca realizar el **desarrollo y despliegue de un modelo supervisado predictivo** bajo una comprensiÃ³n del negocio al que se brinda el proyecto como una soluciÃ³n. 

En este caso, la idea es desarrollar un modelo capaz predecir la **probabilidad de adopciÃ³n de mascotas**, lo cual podrÃ­a ayudar a entidades como los refugios de mascotas a plantear nuevas estrategias para priorizar y optimizar las adopciones.

Todo esto se puede lograr con la ayuda de una **base de datos de mascotas** (en este caso, un dataset de Kaggle) acompaÃ±ada con una **variable objetivo** (como lo es `AdoptionLikelihood` en nuestro dataset), que permita diferenciar a mascotas mÃ¡s fÃ¡ciles de adoptar todo esto **dentro del esquema de MLops**.

[Link del dataset original en Kaggle](https://www.kaggle.com/datasets/rabieelkharoua/predict-pet-adoption-status-dataset/data)

---

## ğŸ•µï¸ Algunos hallazgos del dataset durante la exploraciÃ³n del dataset (comprension_eda.ipynb)

### â„¹ï¸ DescripciÃ³n general de los datos

Este dataset de Kaggle contiene 2007 datos de mascotas en adopciÃ³n, el cuÃ¡l es sintÃ©tico y fue recolectado en un periodo especÃ­fico de tiempo con propÃ³sitos educacionales. 

>[!note]
> Si bien esto **no lo hace ideal para generalizar el comportamiento de las adopciones**, termina siendo ideal para proyectos de Machine Learning o Data Science con interÃ©s de aprender, predecir y entender tendencias de adopciones. 

Estos datos se pueden usar para:

- Modelamiento predictivo para determinar la adoptabilidad de una mascota

- AnÃ¡lisis de impacto de varios factores en las tasas de adopciÃ³n

- Desarrollo de estrategias para incrementar las adopciones.


### ğŸ”ğŸ“‘ğŸ“Š Algunos hallazgos relevantes en la exploraciÃ³n de datos (comprension_eda.ipynb)

â›” No hay nulos, espacios o datos vacÃ­os en el dataset

- Solo se borrÃ³ PetID

- Las mascotas con menos de 50 meses tienden a ser mÃ¡s adoptadas
- Las mascotas con mÃ¡s de 100 meses tienden a ser menos adoptadas

- La diferencia entre mascotas adoptadas y sin adoptar en el dataset es de 1 a 3 (un 33% aprox son adoptadas, un 66% estÃ¡n sin adoptar), lo cual puede ser un desbalanceo que deba considerarse en el modelamiento

Luego de revisar la relaciÃ³n entre variables categÃ³ricas y la variable objetivo:

- Si p â‰ˆ 0 y Cramer's V > 0.3, hay relaciÃ³n real y relevante. Las variables `Size` y `Vaccinated` entran en esta categorÃ­a

- Si p â‰ˆ 0 pero Cramer's V < 0.2 â†’ relaciÃ³n estadÃ­sticamente detectable pero dÃ©bil (`Breed`, `PetType`, `HealthCondition`).

- Si p es grande (ej. 0.37 en Color) â†’ no hay casi evidencia de relaciÃ³n, y ademÃ¡s V confirma que es irrelevante. Por lo que `PreviousOwner` y `Color` pueden no influir mucho en la adoptabilidad.

Posibles reglas de validaciÃ³n de datos:

- `AgeMonths` debe ser >= 0 y < 240.

- `WeightKg` > 0 y < 100.

- Especie que coincida con raza

**[Abrir notebook de comprensiÃ³n_eda.ipynb para ver mÃ¡s detalles](./MLops_pipeline/src/comprension_eda.ipynb)**

---

## ğŸ› ï¸ğŸ‘· Decisiones relevantes en la ingenierÃ­a de caracterÃ­sticas (ft_engineering.py)

- **ImputaciÃ³n de valores faltantes:**  
  Se utilizÃ³ la mediana para variables numÃ©ricas y la moda para las categÃ³ricas, buscando conservar la distribuciÃ³n original sin afectar la varianza de los datos.

- **CodificaciÃ³n de variables categÃ³ricas nominales:**  
  Se usÃ³ `OneHotEncoder`, evitando sesgos ordinales artificiales.

- **EstandarizaciÃ³n / Escalado:**  
  Se aplicÃ³ `MinMaxScaler` para variables numÃ©ricas, permitiendo que todos los atributos estÃ©n en la misma escala.

- **ConversiÃ³n de variables ordinales:**  
  Las variables `Size` y `Color` (ordenado por claridad del color) mapearon a valores numÃ©ricos de acuerdo con su orden lÃ³gico.

- **SeparaciÃ³n de conjuntos:**  
  Los datos se dividieron en entrenamiento (80%) y prueba (20%) para garantizar una evaluaciÃ³n imparcial del modelo.

- **SelecciÃ³n de atributos:**  
  Se eliminaron variables redundantes o irrelevantes (por ejemplo, identificadores Ãºnicos o campos descriptivos de texto no estandarizados).

- **Guardado:**
  Se guarda el procesador y demÃ¡s resultantes como `processed_data.pkl`

**[Puedes abrir ft_engineering.py para ver mÃ¡s detalles](./MLops_pipeline/src/ft_engineering.py)**

## ğŸ§ ğŸ–¥ï¸ SelecciÃ³n del mejor modelo (model_training_evaluation.py)

Luego de comparar el rendimiento mediante conjunto de prueba y validaciÃ³n cruzada, se observa que `RandomForestClassifier` y `GradientBoostingClassifier` ofrecen resultados casi equivalentes.

Sin embargo, `GradientBoosting` presenta un F1 promedio ligeramente superior y una menor desviaciÃ³n estÃ¡ndar, indicando mayor estabilidad ante la variabilidad de los datos.

Por otro lado, `RandomForest` obtuvo la mejor mÃ©trica F1 en el conjunto de prueba individual y es mÃ¡s rÃ¡pido de entrenar e interpretar.

Por lo tanto, se puede escoger segÃºn el criterio de optimizaciÃ³n:

- Si se prioriza rendimiento estable y generalizaciÃ³n, se selecciona `GradientBoosting`.

- Si se prioriza simplicidad y velocidad de ejecuciÃ³n, se mantiene `RandomForest` como modelo final.

Bajo este orden de ideas, se escoge el modelo de `RandomForest` por su simpleza y velocidad de ejecuciÃ³n.

## ğŸ”ğŸ“¶ğŸ–¨ï¸ Monitoreo del model (model_monitoring.py)

Como el dataset no cuenta con datos histÃ³ricos o flujos temporales reales, el monitoreo se diseÃ±Ã³ de manera simulada.

El archivo toma como referencia el conjunto de entrenamiento `X_train` y lo compara con una muestra representativa del conjunto de prueba `X_test` para evaluar posibles desviaciones en la distribuciÃ³n de los datos (data drift)

Se aplicaron pruebas estadÃ­sticas de estabilidad:

- KS Test para variables numÃ©ricas.

- Chi-squared para variables categÃ³ricas.

- PSI (Population Stability Index) para medir el cambio poblacional general.

El resultado puede interpretarse por medio de la aplicaciÃ³n de Streamlit, la cual muestra indicadores visuales de comparaciÃ³n entre distribuciones histÃ³ricas y actuales, permitiendo identificar si el modelo mantiene un comportamiento estable o si se requieren acciones de reentrenamiento.

Para este caso, todos los valores se encuentran dentro de rangos de estabilidad, mostrando que el modelo conserva un desempeÃ±o consistente frente a variaciones moderadas en los datos.

---
## ğŸ“ Estructura del repositorio

<details><summary>(Desplegar para ver la estructura recomendada y planteada en clase)</summary>


```
repo-ML/
â””â”€â”€ MLops_pipeline/
â”‚   â””â”€â”€ src/
â”‚        â”œâ”€â”€ Cargar_datos.ipynb       # Carga de dataset
â”‚        â”œâ”€â”€ comprension_eda.ipynb    # AnÃ¡lisis exploratorio
â”‚        â”œâ”€â”€ ft_engineering.py        # GeneraciÃ³n de features y creaciÃ³n de datasets
â”‚        â”œâ”€â”€ heuristic_model.py       # Modelo base
â”‚        â”œâ”€â”€ model_training.ipynb     # Entrenamiento y comparaciÃ³n de modelos
â”‚        â”œâ”€â”€ model_deploy.ipynb       # Despliegue
â”‚        â”œâ”€â”€ model_evaluation.ipynb   # EvaluaciÃ³n
â”‚        â””â”€â”€ model_monitoring.ipynb   # Monitoreo
â”‚
â”œâ”€â”€ config.json                       # Archivo de configuraciÃ³n de pipeline
â”œâ”€â”€ Base_de_datos.csv                 # Dataset de ejm
â”œâ”€â”€ requirements.txt                  # LibrerÃ­as y dependencias
â”œâ”€â”€ .gitignore                        # Exclusiones de git
â”œâ”€â”€ readme.md                         # DocumentaciÃ³n del proyecto
â””â”€â”€ set_up.bat                        # Script para preparar el entorno
```
</details>

---


Estructura de archivos usados en el proyecto:
```
repo-ML/
â””â”€â”€ MLops_pipeline/
â”‚   â””â”€â”€ src/                        
â”‚        â”œâ”€â”€ config.json                    # Archivo de configuraciÃ³n para setup
â”‚        â”œâ”€â”€ Cargar_datos.ipynb             # Carga de dataset
â”‚        â”œâ”€â”€ comprension_eda.ipynb          # AnÃ¡lisis exploratorio
â”‚        â”œâ”€â”€ ft_engineering.py              # GeneraciÃ³n de features
â”‚        â”œâ”€â”€ model_training_evualation.py   # Entrenamiento y comparaciÃ³n de modelos
â”‚        â”œâ”€â”€ model_monitoring.py            # Monitoreo
â”‚        â”œâ”€â”€ model_deploy.py                # Despliegue (API)
â”‚        â””â”€â”€ app_streamlit.py               # Interfaz visual de streamlit
â”‚
â”œâ”€â”€ Base_de_datos.csv                       # UbicaciÃ³n del dataset
â”œâ”€â”€ requirements.txt                        # LibrerÃ­as y dependencias
â”œâ”€â”€ requirements_docker.txt                 # Dependencias imagen Docker
â”œâ”€â”€ Dockerfile                              # ConfiguraciÃ³n docker
â”œâ”€â”€ .dockerignore                           # Exclusiones de docker
â”œâ”€â”€ .gitignore                              # Exclusiones de git
â”œâ”€â”€ README.md                               # DocumentaciÃ³n del proyecto
â””â”€â”€ set_up.bat                              # Script para preparar el entorno
```
---
## ğŸ›¤ï¸ Flujos de ejecuciÃ³n del repositorio

Teniendo instalado Python, luego de descargar el repositorio y posicionarse en la carpeta raÃ­z:

1. Ejecutar `set_up.bat`, crearÃ¡ el entorno virtual e instalarÃ¡ las librerÃ­as necesarias para la ejecuciÃ³n

2. Inicializar el entorno (lo hace `set_up.bat`)

> Si el entorno no se iniciÃ³ con `set_up.bat`, abrir la terminal de comandos ubicandose en la carpeta raÃ­z y ejecutar el siguiente comando:

```
pet_adoption_ml-venv\Scripts\activate
```
3. Ubicarse en la carpeta src para los demÃ¡s pasos

```
cd .\MLops_pipeline\src\
```

### âš™ï¸ğŸ§‘â€ğŸ’»ğŸ“Š Transformaciones, modelamiento y generaciÃ³n de mÃ©tricas

- GeneraciÃ³n de features:
```
python ft_engineering.py
```
- Entrenamiento y evaluamiento de modelos 
```
python model_training_evaluation.py
```
- Monitoreo
```
python model_monitoring.py
```

> Luego de ejecutar estos pasos, se habrÃ¡n generado archivos de modelos `.pkl` y algunas mÃ©tricas en `.csv` que se usarÃ¡n mÃ¡s adelante.

---

### ğŸ¦„ Despliegue de API con uvicorn
Esta API usa el modelo que mejor se desempeÃ±Ã³ (en nuestro caso, Random Forest) para generar las probabilidad de adopciÃ³n de las mascotas que se le envÃ­en.

```
uvicorn model_deploy:app --reload
```

- Enlace de pruebas: http://127.0.0.1:8000/docs

---

### ğŸ§ª Datos de prueba para los endpoints 

>[!TIP]
> En la secciÃ³n desplegable de abaio se incluyen datos de prueba tanto en formato `.json` como `.csv` que se pueden usar para probar la API. 

<details><summary>(desplegar para ver datos de prueba)</summary>

---

> Endpoint /predict

Mascota con baja adoptabilidad:
```
{
  "PetType": "Rabbit",
  "Breed": "Rabbit",
  "AgeMonths": 70,
  "Color": "Gray",
  "Size": "Small",
  "WeightKg": 3.0,
  "Vaccinated": 0,
  "HealthCondition": 1,
  "TimeInShelterDays": 120,
  "AdoptionFee": 400,
  "PreviousOwner": 0
}
```
Mascota con alta probabilidad:
```
{
  "PetType": "Dog",
  "Breed": "Labrador",
  "AgeMonths": 10,
  "Color": "Brown",
  "Size": "Medium",
  "WeightKg": 18.0,
  "Vaccinated": 1,
  "HealthCondition": 0,
  "TimeInShelterDays": 15,
  "AdoptionFee": 150,
  "PreviousOwner": 1
}
```
Varias mascotas:
```
[
  {
    "PetType": "Dog",
    "Breed": "Golden Retriever",
    "AgeMonths": 8,
    "Color": "White",
    "Size": "Large",
    "WeightKg": 25.0,
    "Vaccinated": 1,
    "HealthCondition": 0,
    "TimeInShelterDays": 10,
    "AdoptionFee": 200,
    "PreviousOwner": 1
  },
  {
    "PetType": "Cat",
    "Breed": "Persian",
    "AgeMonths": 36,
    "Color": "Gray",
    "Size": "Small",
    "WeightKg": 5.0,
    "Vaccinated": 1,
    "HealthCondition": 0,
    "TimeInShelterDays": 60,
    "AdoptionFee": 300,
    "PreviousOwner": 0
  },
  {
    "PetType": "Rabbit",
    "Breed": "Rabbit",
    "AgeMonths": 72,
    "Color": "Brown",
    "Size": "Small",
    "WeightKg": 3.2,
    "Vaccinated": 0,
    "HealthCondition": 1,
    "TimeInShelterDays": 150,
    "AdoptionFee": 450,
    "PreviousOwner": 0
  }
]
```
> Endpoint /predict_batch

en `.csv`:
```
PetType,Breed,AgeMonths,Color,Size,WeightKg,Vaccinated,HealthCondition,TimeInShelterDays,AdoptionFee,PreviousOwner
Dog,Golden Retriever,8,White,Large,25.0,1,0,10,200,1
Cat,Persian,36,Gray,Small,5.0,1,0,60,300,0
Rabbit,Rabbit,72,Brown,Small,3.2,0,1,150,450,0

```

</details>

---
### ğŸ“±ğŸ“¶ EjecuciÃ³n de interfaz grÃ¡fica de Streamlit

Esta interfaz no hace uso de la API, funciona independientemente y usa el modelo `RandomForest` directamente, y tambiÃ©n permite visualizar algunas mÃ©tricas generadas en el monitoreo de datos al ejecutar `model_monitoring.py`.

```
streamlit run app_streamlit.py
```

- Se abre en http://localhost:8501

---

### ğŸ‹ ConstrucciÃ³n y ejecuciÃ³n de imagen de Docker

Hay que ubicarse nuevamente en la carpeta raÃ­z del proyecto 

> Ejecutar el comando si aÃºn se ubica en `/src` :

```
cd ../..
```

Teniendo Docker instalado y en ejecuciÃ³n, se ejecuta el siguiente comando para crear la imagen de la API:

```
docker build -t pet-adoption-api .
```

Ejecutar imagen de la API:

```
docker run -p 8000:8000 pet-adoption-api
```
- Luego de ejecutar la imagen se pueden probar los endpoints en http://localhost:8000/docs



---

## ğŸ“ Resultados de pruebas iniciales en sonarcloud.io

### ğŸ“„ Resumen general
![Resultado de pruebas: Overall code](imgs/sonar_1.png)



- No se detecta cÃ³digo duplicado o con problemas de seguridad considerables
- Se marcan 5 asuntos de fiabilidad, 19 de mantenibilidad y 2 posibles puntos crÃ­ticos de seguridad



### âœ…ğŸ‘Œ Calidad del cÃ³digo: 
- CÃ³digo duplicado: 0.0% Duplications
- Fiabilidad: A, con solo 5 asuntos, los cuales son recomendaciones sobre aÃ±adir hyper parÃ¡metros faltantes en la creaciÃ³n de varios modelos.
- Mantenibilidad: A, significa que el ratio de deuda tÃ©cnica es menor al 5% (solo 19 asuntos):


![](<imgs/sonar_3.png>)
  - Un asunto es sobre el Dockerfile y combinar dos comandos RUN que se ejecutan consecutivamente
    - Se corrige combinando ambos comandos en uno solo
  - Un asunto en app_streamlit.py (para controlar una excepciÃ³n en caso de no cargar el modelo)
    - Se arregla con linea de cÃ³digo que controla la excepciÃ³n
  - 2 asuntos en el .ipynb del EDA sobre cÃ³digo comentado
    - Se arregla fÃ¡cilmente borrando dichos comentarios, consecuentemente tambiÃ©n mejorando la visibilidad del notebook.
  - 4 asuntos en el feature engineering (renombrar una variable para seguir convenciones de Python y memory argument para los pipelines)
    - Se arregla simplemente especÃ­ficando memory=None en los pipelines y renombrando la variable.

![](imgs/sonar_2.png)

  - 2 asuntos en el model_deploy.py sobre remover una variable sin usar y agregar lÃ³gica a un except
    - Se corrige el control de la excepciÃ³n manejando la variable sin usar para la excepciÃ³n
  - 3 asuntos en model_monitoring.py porque se repiten varios Strings en el cÃ³digo que se pueden
    - Se aceptan pero se ignora porque es irrelevante y solo son unos strings para la generaciÃ³n de mÃ©tricas 
  - un asunto en el model_training_evaluation.py sobre especificar memory argument para pipeline
    - Se especifica para corregir y evitar problemas
  - 5 de estos asuntos son todos los asuntos de fiabilidad
    - Se aÃ±adem los hyper parÃ¡metros necesarios a los modelos en model_training_evaluation.py

### ğŸ›¡ï¸ Seguridad: 
- PuntuaciÃ³n de seguridad: A, 0 issues abiertos
- Se detectaron 2 posibles puntos crÃ­ticos de seguridad en el Dockerfile:

![Resultado de pruebas: Overall code](imgs/securityhotspot1.png)
![Resultado de pruebas: Overall code](imgs/securityhotspot2.png)

  - Estos hotspots se arreglan fÃ¡cil corrigiendo el dockerfile para que solamente copie los archivos necesarios y no se ejecute el contenedor con permisos de root.


  ### ğŸ”§ğŸ› ï¸ Resultados luego de manejar los errores:

  ![alt text](imgs/sonar_4.png) 